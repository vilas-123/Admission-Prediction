{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0            118                  4  4.5   4.5  9.65         1\n",
       "1            107                  4  4.0   4.5  8.87         1\n",
       "2            104                  3  3.0   3.5  8.00         1\n",
       "3            110                  3  3.5   2.5  8.67         1\n",
       "4            103                  2  2.0   3.0  8.21         0\n",
       "..           ...                ...  ...   ...   ...       ...\n",
       "495          108                  5  4.5   4.0  9.02         1\n",
       "496          117                  5  5.0   5.0  9.87         1\n",
       "497          120                  5  4.5   5.0  9.56         1\n",
       "498          103                  4  4.0   5.0  8.43         0\n",
       "499          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore from backup\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(df,k, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled= scaler.fit_transform(X_train)\n",
    "X_test_scaled= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, activation='relu', input_dim=6)) \n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m42\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m105\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">658</span> (2.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m658\u001b[0m (2.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">658</span> (2.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m658\u001b[0m (2.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.1889 - val_loss: 0.0769\n",
      "Epoch 2/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0554 - val_loss: 0.0156\n",
      "Epoch 3/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0166 - val_loss: 0.0252\n",
      "Epoch 4/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195 - val_loss: 0.0139\n",
      "Epoch 5/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 6/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 7/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 8/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 9/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 10/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 11/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 12/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 13/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 14/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 15/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 16/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 17/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 18/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 19/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 20/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 21/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 22/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 23/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 24/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 25/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 26/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 27/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 28/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 29/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 30/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 31/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 32/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 33/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 34/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 35/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 36/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 37/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 38/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 39/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 40/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 41/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 42/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 43/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 44/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 45/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 46/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 47/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 48/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 49/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 50/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 51/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 52/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 53/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 54/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 55/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 56/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 57/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 58/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 59/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 60/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 61/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 62/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 63/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 64/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 65/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 66/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 67/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 68/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 69/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 70/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 71/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 72/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 73/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 74/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 75/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 76/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 77/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 78/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 79/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 80/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 81/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 82/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 83/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 84/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 85/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 86/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 87/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 88/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 89/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 90/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 91/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 92/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 93/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 94/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 95/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 96/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 97/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 98/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 99/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 100/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 101/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 102/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 103/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 104/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 105/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 106/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 107/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 108/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 109/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 110/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 111/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 112/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 113/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 114/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 115/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 116/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 117/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 118/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 119/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 120/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 121/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 122/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 123/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 124/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 125/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 126/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 127/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 128/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 129/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 130/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 131/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 132/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 133/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 134/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 135/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 136/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 137/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 138/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 139/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 140/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 141/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 142/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 143/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 144/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 145/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 146/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 147/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 148/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 149/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 150/150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train, validation_split=0.2, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "pred= model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107291868895891"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73d06350f700>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
